import streamlit as st
import pandas as pd
import numpy as np
import pickle
import os
import re

from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans

from ui.ui_components import UIComponents

# Set page config
st.set_page_config(layout="wide")

# Kh·ªüi t·∫°o class
ui = UIComponents()

def show():
    # Set page layout    
    ui.set_page_layout(width=960, hide_branding=False)
    
    # st.title("ƒêi·ªÅu khi·ªÉn Project 2 - Recommendation System")    
    # T·∫°o Menu ·ªü Sidebar
    with st.sidebar:
        # st.title("ƒêi·ªÅu h∆∞·ªõng")
        selected_page = st.radio(                        
            "Ch·ªçn ch·ª©c nƒÉng:",
            ["ƒê·ªÅ xu·∫•t xe theo id", "ƒê·ªÅ xu·∫•t xe theo y√™u c·∫ßu", "Nh√≥m xe theo ƒë·∫∑c ƒëi·ªÉm"]
        )
    
    # Routing logic (G·ªçi h√†m t∆∞∆°ng ·ª©ng theo l·ª±a ch·ªçn)
    if selected_page == "ƒê·ªÅ xu·∫•t xe theo id":
        de_xuat_theo_id()
    elif selected_page == "ƒê·ªÅ xu·∫•t xe theo y√™u c·∫ßu":
        de_xuat_theo_query()
    elif selected_page == "Nh√≥m xe theo ƒë·∫∑c ƒëi·ªÉm":
        group_xe_theo_dac_diem2()
# ============================================================
# H√ÄM X·ª¨ L√ù D·ª∞ ƒêO√ÅN GI√Å XE 
# ============================================================
def load_data(file_path):
    if not os.path.exists(file_path):
        raise FileNotFoundError(file_path)
    
    # ƒê·ªçc d·ªØ li·ªáu t·ª´ file data_motobikes_cleaned.csv    
    df = pd.read_csv(file_path)
    return df

def load_model(model_path):
    if not os.path.exists(model_path):
        raise FileNotFoundError(model_path)

    with open(model_path, 'rb') as file:
        model = pickle.load(file)
    return model

def get_recommendations(df, id, cosine_sim, top_n=3):
    # Tr·∫£ v·ªÅ top_n xe t∆∞∆°ng t·ª± d·ª±a tr√™n Cosine Similarity c·ªßa TF-IDF
    if id not in df['id'].values:
        print(f"Kh√¥ng t√¨m th·∫•y xe c√≥ id '{id}' trong c∆° s·ªü d·ªØ li·ªáu.")
        return pd.DataFrame() # Return an empty DataFrame if no match

    idx = df.index[df['id'] == id][0]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:top_n+1]

    indices = [i[0] for i in sim_scores]

    result = df.iloc[indices][['id','tieu_de','mo_ta_chi_tiet','thuong_hieu','dong_xe','gia','so_km_da_di','nam_dang_ky']].copy()
    result['similarity'] = [round(i[1], 3) for i in sim_scores]
    return result

# Hi·ªÉn th·ªã ƒë·ªÅ xu·∫•t ra b·∫£ng
def display_recommended_bikes(recommended_bikes, cols=5):
    col1, col2, col3 = st.columns(3)
    for i in range(0, len(recommended_bikes), cols):
        cols = st.columns(cols)
        for j, col in enumerate(cols):
            if i + j < len(recommended_bikes):
                bike = recommended_bikes.iloc[i + j]
                with col:
                    bike_description = bike['mo_ta_chi_tiet']
                    truncated_description = ' '.join(bike_description.split()[:100]) + '...'
                    ui.card(
                        title=f"Xe M√°y {i + j + 1}", 
                        content=f"<b>{bike['tieu_de']}</b><br><i>{truncated_description}</i>", 
                        color="#3874b4", icon="üéØ")

# PREPROCESS TEXT (same as training)
def clean_text_vn(text):
    if pd.isna(text):
        return ""
    text = str(text).lower()
    text = re.sub(r"http\S+|www\S+|href\S+", " ", text)
    text = re.sub(r"[^0-9a-zA-Z√Ä-·ªπ\s]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

# H√†m load m√¥ h√¨nh v√† d·ªØ li·ªáu ƒë√£ l∆∞u
def load_models():
    df = pd.read_csv("./data/data_motobikes_cleaned_content_wt.csv")   # UPDATE path if needed

    with open("./models/tfidf_vectorizer.pkl", "rb") as f:
        vectorizer = pickle.load(f)

    with open("./models/tfidf_matrix.pkl", "rb") as f:
        tfidf_matrix = pickle.load(f)

    with open("./models/cosine_sim.pkl", "rb") as f:
        cosine_sim = pickle.load(f)

    return df, vectorizer, tfidf_matrix, cosine_sim

# H√†m ƒë·ªÅ xu·∫•t xe t∆∞∆°ng ƒë·ªìng v·ªõi "N·ªôi dung nh·∫≠p v√†o"
def recommend_from_query(query_text, df, vectorizer, tfidf_matrix, top_n=5):

    clean_query = clean_text_vn(query_text)

    q_vec = vectorizer.transform([clean_query])
    sim_scores = cosine_similarity(q_vec, tfidf_matrix).flatten()

    top_idx = sim_scores.argsort()[::-1][:top_n]

    result = df.iloc[top_idx][[
        'id', 'tieu_de', 'thuong_hieu', 'dong_xe', 'gia',
        'so_km_da_di', 'nam_dang_ky', 'xuat_xu'
    ]].copy()

    result["similarity"] = sim_scores[top_idx].round(4)

    return result.reset_index(drop=True)

# ============================================================
# 3. C√ÅC H√ÄM X·ª¨ L√ù THEO L·ª∞A CH·ªåN ·ªû MENU
# ============================================================

def de_xuat_theo_id():
    ui.centered_text("ƒê·ªÅ xu·∫•t [n] xe m√°y theo ID", color="#1f77b4", size="36px")
    # ui.colored_text("ƒê·ªÅ xu·∫•t [n] xe m√°y theo ID", color="#1f77b4", size="32px", bold=True, italic=False)

    # ƒê·ªçc d·ªØ li·ªáu t·ª´ file data_motobikes_cleaned.csv        
    df_bikes = load_data("./data/data_motobikes_cleaned.csv")   

    # L·∫•y 10 m·∫´u xe m√°y
    random_bikes = df_bikes.head(n=10)    
    st.session_state.random_bikes = random_bikes
        
    # Ki·ªÉm tra xem 'selected_bike_id' ƒë√£ c√≥ trong session_state hay ch∆∞a
    if 'selected_bike_id' not in st.session_state:
        # N·∫øu ch∆∞a c√≥, thi·∫øt l·∫≠p gi√° tr·ªã m·∫∑c ƒë·ªãnh l√† None ho·∫∑c ID kh√°ch s·∫°n ƒë·∫ßu ti√™n
        st.session_state.selected_bike_id = None

    # Theo c√°ch cho ng∆∞·ªùi d√πng ch·ªçn kh√°ch s·∫°n t·ª´ dropdown
    # T·∫°o m·ªôt tuple cho m·ªói kh√°ch s·∫°n, trong ƒë√≥ ph·∫ßn t·ª≠ ƒë·∫ßu l√† t√™n v√† ph·∫ßn t·ª≠ th·ª© hai l√† ID
    bike_options = [(row['tieu_de'], row['id']) for index, row in st.session_state.random_bikes.iterrows()]
    # st.session_state.random_bikes
    # T·∫°o m·ªôt dropdown v·ªõi options l√† c√°c tuple n√†y
    selected_bike = st.selectbox(
        "H√£y ch·ªçn xe m√°y b·∫°n quan t√¢m:",
        options=bike_options,
        format_func=lambda x: x[0]  # Hi·ªÉn th·ªã t√™n xe m√°y
    )
    # Display the selected bike
    # st.write("B·∫°n ƒë√£ ch·ªçn:", selected_bike)

    # C·∫≠p nh·∫≠t session_state d·ª±a tr√™n l·ª±a ch·ªçn hi·ªán t·∫°i
    st.session_state.selected_bike_id = selected_bike[1]

    # Open and load file to cosine_sim_new
    with open('./models/cosine_sim.pkl', 'rb') as f:
        cosine_sim_new = pickle.load(f)

    if st.session_state.selected_bike_id:
        # ui.badge("bike_ID: " + str(st.session_state.selected_bike_id), color="#007bff")
        # st.write("bike_ID: ", st.session_state.selected_bike_id)
        # Hi·ªÉn th·ªã th√¥ng tin xe m√°y ƒë∆∞·ª£c ch·ªçn
        selected_bike = df_bikes[df_bikes['id'] == st.session_state.selected_bike_id]

        if not selected_bike.empty:
            bike_description = selected_bike['mo_ta_chi_tiet'].values[0]
            # truncated_description = ' '.join(bike_description.split()[:100]) + '...'

            # ui.colored_text("Xe m√°y ƒë∆∞·ª£c ch·ªçn", color="#1f77b4", size="32px", bold=True, italic=False)
            ui.section_title("Xe m√°y ƒë∆∞·ª£c ch·ªçn " + f"(ID: {str(st.session_state.selected_bike_id)})", selected_bike['tieu_de'].values[0], "Th√¥ng tin: " + bike_description)           
                        
            st.write("---")
            ui.colored_text("üîç C√°c xe m√°y kh√°c b·∫°n c≈©ng c√≥ th·ªÉ quan t√¢m:", color="#ce7018", size="28px", bold=True, italic=False)            

            recommendations = get_recommendations(df_bikes, st.session_state.selected_bike_id, cosine_sim=cosine_sim_new, top_n=3) 
            display_recommended_bikes(recommendations, cols=3)
        else:
            st.write(f"Kh√¥ng t√¨m th·∫•y xe m√°y v·ªõi ID: {st.session_state.selected_bike_id}")

    def de_xuat_theo_query():    
        st.subheader("ƒê·ªÅ xu·∫•t n xe m√°y theo y√™u c·∫ßu ng∆∞·ªùi d√πng nh·∫≠p")

    def group_xe_theo_dac_diem():    
        st.subheader("Nh√≥m c√°c xe m√°y theo ƒë·∫∑c ƒëi·ªÉm chung")


def de_xuat_theo_query():    
    ui.centered_text("G·ª£i √Ω xe d·ª±a tr√™n m√¥ t·∫£", color="#1f77b4", size="36px")
    st.write("Nh·∫≠p m√¥ t·∫£ xe b·∫°n mu·ªën t√¨m, h·ªá th·ªëng s·∫Ω g·ª£i √Ω nh·ªØng xe ph√π h·ª£p nh·∫•t.")

    # Load model & data
    df, vectorizer, tfidf_matrix, cosine_sim = load_models()

    # Input box
    query = st.text_input(
        "Nh·∫≠p m√¥ t·∫£ xe:",
        placeholder="V√≠ d·ª•: xe SH Vi·ªát Nam gi√° kho·∫£ng 65000000",
        value="xe SH Vi·ªát Nam gi√° kho·∫£ng 65000000",
    )

    # Top-N slider
    top_n = st.slider("S·ªë l∆∞·ª£ng g·ª£i √Ω mu·ªën xem:", 3, 10, 5)

    # Button
    if st.button("üîç G·ª£i √Ω ngay"):
        if query.strip() == "":
            st.warning("‚ö† Vui l√≤ng nh·∫≠p m√¥ t·∫£ tr∆∞·ªõc khi t√¨m ki·∫øm.")
        else:
            st.write("### üìå K·∫øt qu·∫£ g·ª£i √Ω:")
            result = recommend_from_query(query, df, vectorizer, tfidf_matrix, top_n)

            # Format clickable link
            def linkify(url):
                return f"[M·ªü tin ƒëƒÉng]({url})"

            st.dataframe(result[[
                "id", "tieu_de", "thuong_hieu", "dong_xe", "gia",
                "similarity"
            ]])

def group_xe_theo_dac_diem():
    ui.centered_text("Nh√≥m c√°c xe m√°y theo ƒë·∫∑c ƒëi·ªÉm k·ªπ thu·∫≠t chung", color="#1f77b4", size="36px")    
    import streamlit as st
    import pandas as pd
    import matplotlib.pyplot as plt
    

    # =====================================================
    # STREAMLIT UI ‚Äì PCA CLUSTER DEMO
    # =====================================================

    ui.colored_text("PCA Scatter Plot ‚Äì Demo Cluster (K=4)", color="#111111", size="32px", bold=True)        
    st.write("Tr·ª±c quan h√≥a ph√¢n c·ª•m xe theo ƒë·∫∑c ƒëi·ªÉm k·ªπ thu·∫≠t (Demo K=4).")

    # ============================
    # STEP 1 ‚Äî Upload File
    # ============================
    """
    uploaded_file = st.file_uploader(
        "Upload file data_motobikes_cleaned.csv",
        type=["csv"]
    )

    if uploaded_file is None:
        st.warning("‚ö† Vui l√≤ng upload file CSV ƒë·ªÉ ti·∫øp t·ª•c.")
        st.stop()
    """
    
    uploaded_file = "./data/data_motobikes_cleaned_content_wt.csv"
    # Load dataframe
    df = pd.read_csv(uploaded_file)
    # st.success("üìÅ File ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n th√†nh c√¥ng!")

    # ============================
    # STEP 2 ‚Äî Select numeric features
    # ============================
    st.subheader("üßÆ Ch·ªçn c√°c thu·ªôc t√≠nh numeric ƒë·ªÉ ph√¢n c·ª•m")

    num_cols_default = ["gia", "so_km_da_di", "nam_dang_ky"]
    num_cols = st.multiselect(
        "Ch·ªçn c·ªôt numeric:",
        options=df.columns.tolist(),
        default=num_cols_default
    )

    if len(num_cols) < 2:
        st.error("‚ö† C·∫ßn ch·ªçn √≠t nh·∫•t 2 c·ªôt numeric!")
        st.stop()

    X = df[num_cols].fillna(0)

    # ============================
    # STEP 3 ‚Äî Normalize
    # ============================
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # ============================
    # STEP 4 ‚Äî KMeans (Demo K=4)
    # ============================
    k = 4
    kmeans = KMeans(n_clusters=k, random_state=42)
    df["cluster_demo"] = kmeans.fit_predict(X_scaled)

    # ============================
    # STEP 5 ‚Äî PCA Projection
    # ============================
    pca = PCA(n_components=2, random_state=42)
    pca_comp = pca.fit_transform(X_scaled)
    df["pca1"] = pca_comp[:, 0]
    df["pca2"] = pca_comp[:, 1]

    # ============================
    # STEP 6 ‚Äî Scatter Plot PCA
    # ============================
    st.subheader("üìà PCA Scatter Plot Visualization")

    fig, ax = plt.subplots(figsize=(10, 7))
    colors = ["red", "green", "blue", "purple"]

    for cluster_id, color in zip(sorted(df["cluster_demo"].unique()), colors):
        subset = df[df["cluster_demo"] == cluster_id]
        ax.scatter(subset["pca1"], subset["pca2"], 
                s=25, alpha=0.7, label=f"Cluster {cluster_id}", color=color)

    ax.set_title("PCA Scatter Plot ‚Äì Demo Market Segmentation (K=4)", fontsize=14)
    ax.set_xlabel("PCA Component 1")
    ax.set_ylabel("PCA Component 2")
    ax.legend()
    ax.grid(alpha=0.2)

    st.pyplot(fig)

    # ============================
    # STEP 7 ‚Äî Cluster Statistics
    # ============================
    st.subheader("üìä Th·ªëng k√™ theo c·ª•m")

    cluster_summary = df.groupby("cluster_demo")[num_cols].mean().round(2)
    st.dataframe(cluster_summary)

    # ============================
    # STEP 8 ‚Äî Sample of each cluster
    # ============================
    st.subheader("üìå V√≠ d·ª• m·ªôt v√†i xe trong t·ª´ng c·ª•m")

    for c in sorted(df["cluster_demo"].unique()):
        st.markdown(f"### üîπ Cluster {c}")
        st.dataframe(df[df["cluster_demo"] == c].head(5)[["tieu_de", "thuong_hieu", "dong_xe", "gia"]])

def group_xe_theo_dac_diem2():
    import streamlit as st
    import pandas as pd
    import numpy as np
    from sklearn.decomposition import PCA
    from sklearn.manifold import TSNE
    import matplotlib.pyplot as plt
    import seaborn as sns

    st.set_page_config(page_title="t-SNE Cluster Visualization", layout="wide")

    st.title("üîç t-SNE Visualization for Motorbike Clustering")
    
    uploaded_file = "./data/data_motobikes_cleaned_content_wt.csv"
    df = pd.read_csv(uploaded_file)    
    st.write(df.head())

    # ==============================
    # 2. Select numeric features
    # ==============================
    st.subheader("‚öôÔ∏è Select numeric features for visualization")

    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

    selected_features = st.multiselect(
        "Ch·ªçn c√°c c·ªôt ƒë·ªÉ ch·∫°y PCA + t-SNE:",
        numeric_cols,
        default=numeric_cols[:6]  # ch·ªçn m·ªôt s·ªë c·ªôt ƒë·∫ßu ti√™n l√†m m·∫∑c ƒë·ªãnh
    )

    cluster_col = st.selectbox(
        "Ch·ªçn c·ªôt cluster ƒë·ªÉ ph√¢n m√†u:",
        df.columns,
        index=list(df.columns).index("cluster") if "cluster" in df.columns else 0
    )

    if st.button("üöÄ Run PCA + t-SNE"):
        if len(selected_features) < 2:
            st.error("‚ö†Ô∏è C·∫ßn ch·ªçn √≠t nh·∫•t 2 ƒë·∫∑c tr∆∞ng!")
            st.stop()

        X = df[selected_features].fillna(0).values

        # ==============================
        # 3. PCA reduction (50D)
        # ==============================
        st.write("üîÑ Running PCA...")
        pca = PCA(n_components=min(50, X.shape[1]), random_state=42)
        X_pca = pca.fit_transform(X)

        # ==============================
        # 4. t-SNE Reduction
        # ==============================
        perplexity = st.slider("Perplexity", 5, 50, 30)

        st.write("üé® Running t-SNE (this may take a moment)...")
        tsne = TSNE(
            n_components=2,
            perplexity=perplexity,
            learning_rate="auto",
            init="pca",
            random_state=42
        )

        X_tsne = tsne.fit_transform(X_pca)

        tsne_df = pd.DataFrame({
            "tsne_1": X_tsne[:, 0],
            "tsne_2": X_tsne[:, 1],
            "cluster": df[cluster_col].astype(str)
        })

        # ==============================
        # 5. Plot t-SNE
        # ==============================
        st.subheader("üìå t-SNE Scatter Plot")

        plt.figure(figsize=(10, 7))
        sns.scatterplot(
            data=tsne_df,
            x="tsne_1",
            y="tsne_2",
            hue="cluster",
            palette="tab10",
            s=20,
            alpha=0.8
        )
        plt.title("t-SNE Visualization of Motorbike Clusters")
        plt.xlabel("t-SNE 1")
        plt.ylabel("t-SNE 2")
        plt.legend(title="Cluster")

        st.pyplot(plt)

        # ==============================
        # 6. Show cluster distribution
        # ==============================
        st.subheader("üìä Cluster Distribution")
        st.bar_chart(tsne_df["cluster"].value_counts())
